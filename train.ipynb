{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "754ad47f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchvision\n",
            "  Using cached torchvision-0.25.0-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from torchvision) (2.4.2)\n",
            "Requirement already satisfied: torch==2.10.0 in ./.venv/lib/python3.11/site-packages (from torchvision) (2.10.0)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision)\n",
            "  Downloading pillow-12.1.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch==2.10.0->torchvision) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.11/site-packages (from torch==2.10.0->torchvision) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.11/site-packages (from torch==2.10.0->torchvision) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.11/site-packages (from torch==2.10.0->torchvision) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch==2.10.0->torchvision) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.11/site-packages (from torch==2.10.0->torchvision) (2026.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch==2.10.0->torchvision) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch==2.10.0->torchvision) (3.0.3)\n",
            "Downloading torchvision-0.25.0-cp311-cp311-macosx_11_0_arm64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m eta \u001b[36m0:00:01\u001b[0m0m\n",
            "\u001b[?25hDownloading pillow-12.1.1-cp311-cp311-macosx_11_0_arm64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m  \u001b[33m0:00:03\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow, torchvision\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torchvision]\u001b[0m [torchvision]\n",
            "\u001b[1A\u001b[2KSuccessfully installed pillow-12.1.1 torchvision-0.25.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torchvision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "48599dc2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.8.2-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in ./.venv/lib/python3.11/site-packages (from torchmetrics) (2.4.2)\n",
            "Requirement already satisfied: packaging>17.1 in ./.venv/lib/python3.11/site-packages (from torchmetrics) (26.0)\n",
            "Requirement already satisfied: torch>=2.0.0 in ./.venv/lib/python3.11/site-packages (from torchmetrics) (2.10.0)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.15.2-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: setuptools in ./.venv/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (65.5.0)\n",
            "Requirement already satisfied: typing_extensions in ./.venv/lib/python3.11/site-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.15.0)\n",
            "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.20.3)\n",
            "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in ./.venv/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in ./.venv/lib/python3.11/site-packages (from torch>=2.0.0->torchmetrics) (2026.2.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.11/site-packages (from sympy>=1.13.3->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.3)\n",
            "Downloading torchmetrics-1.8.2-py3-none-any.whl (983 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m983.2/983.2 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.15.2-py3-none-any.whl (29 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2/2\u001b[0m [torchmetrics][0m [torchmetrics]\n",
            "\u001b[1A\u001b[2KSuccessfully installed lightning-utilities-0.15.2 torchmetrics-1.8.2\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "4b98241a",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (1.26.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "a64b37de",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ]
        }
      ],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "b24e61fd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/arasvalizadeh/Desktop/folders/term 7/ML/Project\n"
          ]
        }
      ],
      "source": [
        "%cd \"/Users/arasvalizadeh/Desktop/folders/term 7/ML/Project\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "66dda4bb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import config\n",
        "from dataset.face_dataset import FaceDataset\n",
        "from models.unet import UNet\n",
        "from losses.losees import get_loss, get_identity_loss\n",
        "from utils.device import get_device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "af9cbb4c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def save_curves(train_losses: list[float], val_losses: list[float]) -> None:\n",
        "    os.makedirs(config.RESULTS_DIR, exist_ok=True)\n",
        "    plt.figure()\n",
        "    plt.plot(train_losses, label=\"Train L1 Loss\")\n",
        "    plt.plot(val_losses, label=\"Val L1 Loss\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.savefig(os.path.join(config.RESULTS_DIR, \"loss_curve.png\"))\n",
        "    plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d3a4c6e2",
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_l1_loss(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total = 0.0\n",
        "    for degraded, clean in loader:\n",
        "        degraded = degraded.to(device)\n",
        "        clean = clean.to(device)\n",
        "        output = model(degraded)\n",
        "        total += criterion(output, clean).item()\n",
        "    return total / len(loader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "96709b9e",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20 | Train L1 Loss: 0.2640 | Val L1 Loss: 0.2549\n",
            "Best model saved.\n",
            "Epoch 2/20 | Train L1 Loss: 0.2211 | Val L1 Loss: 0.1592\n",
            "Best model saved.\n",
            "Epoch 3/20 | Train L1 Loss: 0.1135 | Val L1 Loss: 0.1009\n",
            "Best model saved.\n",
            "Epoch 4/20 | Train L1 Loss: 0.0936 | Val L1 Loss: 0.0888\n",
            "Best model saved.\n",
            "Epoch 5/20 | Train L1 Loss: 0.0852 | Val L1 Loss: 0.0851\n",
            "Best model saved.\n",
            "Epoch 6/20 | Train L1 Loss: 0.0812 | Val L1 Loss: 0.0836\n",
            "Best model saved.\n",
            "Epoch 7/20 | Train L1 Loss: 0.0788 | Val L1 Loss: 0.0756\n",
            "Best model saved.\n",
            "Epoch 8/20 | Train L1 Loss: 0.0765 | Val L1 Loss: 0.0741\n",
            "Best model saved.\n",
            "Epoch 9/20 | Train L1 Loss: 0.0756 | Val L1 Loss: 0.0758\n",
            "No improvement for 1/5 epochs.\n",
            "Epoch 10/20 | Train L1 Loss: 0.0731 | Val L1 Loss: 0.0693\n",
            "Best model saved.\n",
            "Epoch 11/20 | Train L1 Loss: 0.0702 | Val L1 Loss: 0.0691\n",
            "Best model saved.\n",
            "Epoch 12/20 | Train L1 Loss: 0.0686 | Val L1 Loss: 0.0662\n",
            "Best model saved.\n",
            "Epoch 13/20 | Train L1 Loss: 0.0658 | Val L1 Loss: 0.0649\n",
            "Best model saved.\n",
            "Epoch 14/20 | Train L1 Loss: 0.0640 | Val L1 Loss: 0.0631\n",
            "Best model saved.\n",
            "Epoch 15/20 | Train L1 Loss: 0.0646 | Val L1 Loss: 0.0622\n",
            "Best model saved.\n",
            "Epoch 16/20 | Train L1 Loss: 0.0633 | Val L1 Loss: 0.0631\n",
            "No improvement for 1/5 epochs.\n",
            "Epoch 17/20 | Train L1 Loss: 0.0619 | Val L1 Loss: 0.0606\n",
            "Best model saved.\n",
            "Epoch 18/20 | Train L1 Loss: 0.0623 | Val L1 Loss: 0.0641\n",
            "No improvement for 1/5 epochs.\n",
            "Epoch 19/20 | Train L1 Loss: 0.0628 | Val L1 Loss: 0.0603\n",
            "Best model saved.\n",
            "Epoch 20/20 | Train L1 Loss: 0.0620 | Val L1 Loss: 0.0606\n",
            "No improvement for 1/5 epochs.\n"
          ]
        }
      ],
      "source": [
        "device = get_device()\n",
        "\n",
        "use_align = getattr(config, \"USE_ALIGNMENT\", False)\n",
        "img_size = getattr(config, \"IMG_SIZE\", 128)\n",
        "train_dataset = FaceDataset(config.DATA_TRAIN_DIR, config.DESTRUCTION, use_alignment=use_align, img_size=img_size)\n",
        "train_loader = DataLoader(train_dataset, batch_size=config.BATCH_SIZE, shuffle=True)\n",
        "\n",
        "val_dataset = FaceDataset(config.DATA_VAL_DIR, config.DESTRUCTION, use_alignment=use_align, img_size=img_size)\n",
        "val_loader = DataLoader(val_dataset, batch_size=config.BATCH_SIZE, shuffle=False)\n",
        "\n",
        "model = UNet().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=config.LR)\n",
        "criterion = get_loss()\n",
        "identity_loss_fn = get_identity_loss(device) if getattr(config, \"USE_IDENTITY_LOSS\", False) else None\n",
        "\n",
        "best_loss = float(\"inf\")\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "patience = getattr(config, \"EARLY_STOPPING_PATIENCE\", 5)\n",
        "min_delta = getattr(config, \"EARLY_STOPPING_MIN_DELTA\", 0.05)\n",
        "epochs_no_improve = 0\n",
        "\n",
        "for epoch in range(config.EPOCHS):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    for degraded, clean in train_loader:\n",
        "        degraded = degraded.to(device)\n",
        "        clean = clean.to(device)\n",
        "\n",
        "        output = model(degraded)\n",
        "        loss = criterion(output, clean)\n",
        "        if identity_loss_fn is not None:\n",
        "            loss = loss + getattr(config, 'IDENTITY_LOSS_WEIGHT', 0.1) * identity_loss_fn(output, clean)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    epoch_loss /= len(train_loader)\n",
        "    train_losses.append(epoch_loss)\n",
        "\n",
        "    val_loss_epoch = compute_l1_loss(model, val_loader, criterion, device)\n",
        "    val_losses.append(val_loss_epoch)\n",
        "\n",
        "    print(\n",
        "        f\"Epoch {epoch + 1}/{config.EPOCHS} | \"\n",
        "        f\"Train L1 Loss: {epoch_loss:.4f} | \"\n",
        "        f\"Val L1 Loss: {val_loss_epoch:.4f}\"\n",
        "    )\n",
        "\n",
        "    # Save best model + early stopping (L1: lower is better)\n",
        "    if val_loss_epoch < best_loss :\n",
        "        best_loss = val_loss_epoch\n",
        "        torch.save(model.state_dict(), config.MODEL_PATH)\n",
        "        print(\"Best model saved.\")\n",
        "        epochs_no_improve = 0\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"No improvement for {epochs_no_improve}/{patience} epochs.\")\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\"Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    save_curves(train_losses, val_losses)\n",
        "\n",
        "# final save curves (in case loop ended early)\n",
        "save_curves(train_losses, val_losses)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
